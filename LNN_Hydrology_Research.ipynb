{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Liquid Neural Networks for Hydrological Inflow Forecasting\n\n",
    "This notebook presents a comprehensive analysis of Liquid Neural Networks (LNNs) for hydrological time series forecasting. We compare the performance of LNNs against traditional recurrent neural networks (RNNs) like LSTM and GRU, as well as 1D-CNNs, on a real-world rainfall-inflow dataset.\n\n",
    "The primary objectives of this study are:\n",
    "1. To evaluate the effectiveness of LNNs in a hydrological context.\n",
    "2. To benchmark LNN performance against established deep learning models.\n",
    "3. To explore advanced LNN capabilities, such as handling irregular time series and providing uncertainty estimates.\n\n",
    "This notebook is structured to be a reproducible research artifact, including detailed explanations, code, and a series of 10 structured experiments to thoroughly investigate the properties of LNNs."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Setup and Imports\n\n",
    "First, we import the necessary libraries for data manipulation, modeling, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchdiffeq import odeint\n",
    "import time\n",
    "import json\n\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from IPython.display import Markdown, display\n\n",
    "mpl.rcParams['figure.figsize'] = (10, 8)\n",
    "mpl.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Data Loading and Preprocessing\n\n",
    "We load and preprocess the dataset. This includes converting the 'Date' column, setting it as the index, and scaling all numerical features to a [0, 1] range using `MinMaxScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_path = \"final_inflow_rainfall_merged.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.set_index('Date', inplace=True)\n\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(df.values)\n\n",
    "df_scaled = pd.DataFrame(data_scaled, columns=df.columns, index=df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating Time Series Sequences\n\n",
    "We create sequences of data for our time series models. Each sample will consist of a window of 5 previous days (`win_length`) to predict the next day's inflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_sequences(data, target_col, win_length):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for i in range(len(data) - win_length):\n",
    "        seq = data[i:i+win_length]\n",
    "        label = data[i+win_length:i+win_length+1, target_col]\n",
    "        sequences.append(seq)\n",
    "        labels.append(label)\n",
    "    return np.array(sequences), np.array(labels)\n\n",
    "win_length = 5\n",
    "target_col_index = df.columns.get_loc('Inflows in last 24 Hrs. in Mcft.')\n",
    "X, y = create_sequences(data_scaled, target_col_index, win_length)\n\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123, shuffle=False)\n\n",
    "# Convert to PyTorch Tensors\n",
    "X_train_t = torch.from_numpy(X_train).float()\n",
    "y_train_t = torch.from_numpy(y_train).float()\n",
    "X_test_t = torch.from_numpy(X_test).float()\n",
    "y_test_t = torch.from_numpy(y_test).float()\n\n",
    "# Create DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(TensorDataset(X_train_t, y_train_t), batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(TensorDataset(X_test_t, y_test_t), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Model Implementation and Training\n\n",
    "We define all models within the PyTorch framework for consistent comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, epochs=50, lr=0.001):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.1. TrueLNN Model (with torchdiffeq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ODEF(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(ODEF, self).__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(hidden_size, hidden_size), nn.Tanh(), nn.Linear(hidden_size, hidden_size))\n",
    "    def forward(self, t, x):\n",
    "        return self.net(x)\n\n",
    "class TrueLNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(TrueLNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_to_hidden = nn.Linear(input_size, hidden_size)\n",
    "        self.ode_func = ODEF(hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        h_t = torch.zeros(batch_size, self.hidden_size)\n",
    "        for t in range(x.size(1)):\n",
    "            input_t = self.input_to_hidden(x[:, t, :])\n",
    "            h_t = odeint(self.ode_func, h_t + input_t, torch.tensor([0, 1]), method='rk4')[1]\n",
    "        return self.fc(h_t)\n\n",
    "lnn_model = TrueLNN(X_train.shape[2], 128, 1)\n",
    "print(\"Training TrueLNN...\")\n",
    "lnn_model = train_model(lnn_model, train_loader, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.2. Baseline Models (LSTM, GRU, 1D-CNN) in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        return self.fc(out[:, -1, :])\n\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    def forward(self, x):\n",
    "        out, _ = self.gru(x)\n",
    "        return self.fc(out[:, -1, :])\n\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1d = nn.Conv1d(input_size, 128, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(128 * win_length, output_size)\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1) # (B, F, T)\n",
    "        x = self.relu(self.conv1d(x))\n",
    "        x = self.flatten(x)\n",
    "        return self.fc(x)\n\n",
    "# Train baseline models\n",
    "lstm_torch_model = LSTMModel(X_train.shape[2], 128, 1)\n",
    "gru_torch_model = GRUModel(X_train.shape[2], 128, 1)\n",
    "cnn_torch_model = CNNModel(X_train.shape[2], 1)\n\n",
    "print(\"Training PyTorch LSTM...\")\n",
    "lstm_torch_model = train_model(lstm_torch_model, train_loader)\n",
    "print(\"\\nTraining PyTorch GRU...\")\n",
    "gru_torch_model = train_model(gru_torch_model, train_loader)\n",
    "print(\"\\nTraining PyTorch 1D-CNN...\")\n",
    "cnn_torch_model = train_model(cnn_torch_model, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Model Evaluation and Comparison\n\n",
    "We evaluate all models on the test set and compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = {}\n",
    "df_final = df.iloc[len(df) - len(y_test) + win_length - 1:].copy()\n",
    "actual = df_final['Inflows in last 24 Hrs. in Mcft.']\n\n",
    "# TensorFlow models\n",
    "for name, model in models.items():\n",
    "    preds_scaled = model.predict(test_generator)\n",
    "    preds_inv = inverse_transform_predictions(preds_scaled, X_test, scaler, win_length)\n",
    "    df_final[f'{name}_Pred'] = preds_inv\n",
    "    mse = mean_squared_error(actual, preds_inv)\n",
    "    results[name] = {'RMSE': np.sqrt(mse), 'MSE': mse, 'R-squared': r2_score(actual, preds_inv), 'MAE': mean_absolute_error(actual, preds_inv)}\n\n",
    "# PyTorch LNN\n",
    "lnn_model.eval()\n",
    "with torch.no_grad():\n",
    "    preds_lnn_scaled = lnn_model(X_test_t).numpy()\n",
    "preds_lnn_inv = inverse_transform_predictions(preds_lnn_scaled, X_test, scaler, win_length)\n",
    "df_final['LNN_Pred'] = preds_lnn_inv\n",
    "mse_lnn = mean_squared_error(actual, preds_lnn_inv)\n",
    "results['LNN'] = {'RMSE': np.sqrt(mse_lnn), 'MSE': mse_lnn, 'R-squared': r2_score(actual, preds_lnn_inv), 'MAE': mean_absolute_error(actual, preds_lnn_inv)}\n\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"Model Performance Metrics:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Advanced LNN Experiments\n\n",
    "This section will contain the implementation of the 10 advanced experiments to further explore the capabilities of LNNs."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.1. Experiment 1: Building the LNN Inflow Benchmark\n\n",
    "To facilitate future research and ensure reproducibility, we will structure our dataset into a format suitable for sharing on platforms like Hugging Face. This involves creating clear train, validation, and test splits.\n\n",
    "**Note:** For this experiment, we define a function that would save the data. The actual file saving is commented out to prevent writing to the local filesystem during this automated run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def prepare_huggingface_dataset(df, train_ratio=0.7, val_ratio=0.15):\n",
    "    # We respect the water-year (Oct-Sep), but for simplicity here, we'll do a standard time-based split\n",
    "    train_end = int(len(df) * train_ratio)\n",
    "    val_end = int(len(df) * (train_ratio + val_ratio))\n",
    "\n",
    "    train_df = df.iloc[:train_end]\n",
    "    val_df = df.iloc[train_end:val_end]\n",
    "    test_df = df.iloc[val_end:]\n",
    "\n",
    "    print(f\"Training set size: {len(train_df)}\")\n",
    "    print(f\"Validation set size: {len(val_df)}\")\n",
    "    print(f\"Test set size: {len(test_df)}\")\n",
    "\n",
    "    # To save for Hugging Face (example):\n",
    "    # train_df.to_csv('train_inflow_data.csv')\n",
    "    # val_df.to_csv('validation_inflow_data.csv')\n",
    "    # test_df.to_csv('test_inflow_data.csv')\n",
    "    \n",
    "    return train_df, val_df, test_df\n\n",
    "train_split, val_split, test_split = prepare_huggingface_dataset(df.reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.2. Experiment 2: Irregular-Time Challenge\n\n",
    "LNNs are theoretically well-suited for irregularly sampled data. We test this by re-sampling the data, keeping only days with rainfall > 5mm, and training the LNN on this non-uniform grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rainfall_cols = [col for col in df.columns if col.startswith('1')]\n",
    "df_irregular = df[df[rainfall_cols].sum(axis=1) > 5].copy()\n\n",
    "print(f\"Original dataset size: {len(df)}\")\n",
    "print(f\"Irregular dataset size: {len(df_irregular)}\")\n\n",
    "# Preprocess and create a generator for the irregular data\n",
    "data_irregular_scaled = scaler.transform(df_irregular[df.columns[0:]].values)\n",
    "features_irr = data_irregular_scaled\n",
    "target_irr = data_irregular_scaled[:, 0]\n\n",
    "X_irr, y_irr = create_sequences(features_irr, 0, win_length)\n",
    "X_irr_t = torch.from_numpy(X_irr).float()\n",
    "y_irr_t = torch.from_numpy(y_irr).float()\n\n",
    "irr_train_loader = DataLoader(TensorDataset(X_irr_t, y_irr_t), batch_size=batch_size, shuffle=False)\n\n",
    "# Train a new LNN on the irregular data\n",
    "lnn_irr_model = TrueLNN(num_features, 128, 1)\n",
    "print(\"\\nTraining LNN on irregular data:\")\n",
    "lnn_irr_model = train_model(lnn_irr_model, irr_train_loader, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.3. Experiment 3: Spatial Ablation via 'Liquid Connectivity'\n\n",
    "We treat the 22 rain gauges as a graph and allow the LNN to learn an adaptive time constant for each, effectively learning the importance of each gauge. We then prune gauges with high time constants (low relevance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class SpatiallyAwareLNN(TrueLNN):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SpatiallyAwareLNN, self).__init__(input_size, hidden_size, output_size)\n",
    "        self.time_constants = nn.Parameter(torch.randn(input_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        h_t = torch.zeros(batch_size, self.hidden_size)\n",
    "        \n",
    "        for t in range(x.size(1)):\n",
    "            # Apply learnable time constants to input features\n",
    "            input_t = self.input_to_hidden(x[:, t, :] * torch.sigmoid(self.time_constants))\n",
    "            h_t = odeint(self.ode_func, h_t + input_t, torch.tensor([0, 1]), method='rk4')[1]\n",
    "            \n",
    "        out = self.fc(h_t)\n",
    "        return out\n\n",
    "# Initialize and train the spatially aware LNN\n",
    "lnn_spatial_model = SpatiallyAwareLNN(num_features, 128, 1)\n",
    "print(\"\\nTraining Spatially Aware LNN:\")\n",
    "lnn_spatial_model = train_model(lnn_spatial_model, train_loader, epochs=50)\n\n",
    "# Prune and visualize the learned time constants\n",
    "learned_tau = torch.sigmoid(lnn_spatial_model.time_constants).detach().numpy()\n",
    "pruning_threshold = 0.1 # Prune if learned weight is less than 0.1\n\n",
    "relevant_gauges = [df.columns[i] for i, tau in enumerate(learned_tau) if tau > pruning_threshold]\n",
    "print(f\"\\nRelevant Gauges (learned weight > {pruning_threshold}):\")\n",
    "print(relevant_gauges)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.4. Experiment 4: Uncertainty-Aware LNN (UA-LNN) for Flood-Risk\n\n",
    "We implement Monte Carlo (MC) dropout within the LNN to capture uncertainty. This involves adding dropout layers and running multiple forward passes during inference to generate a distribution of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class UA_LNN(TrueLNN):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout_rate=0.3):\n",
    "        super(UA_LNN, self).__init__(input_size, hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        h_t = torch.zeros(batch_size, self.hidden_size)\n",
    "        \n",
    "        for t in range(x.size(1)):\n",
    "            input_t = self.input_to_hidden(x[:, t, :])\n",
    "            # Apply dropout within the ODE solver step\n",
    "            h_t = odeint(self.ode_func, h_t + self.dropout(input_t), torch.tensor([0, 1]), method='rk4')[1]\n",
    "            \n",
    "        out = self.fc(h_t)\n",
    "        return out\n\n",
    "# Initialize and train the UA-LNN\n",
    "ua_lnn_model = UA_LNN(num_features, 128, 1)\n",
    "optimizer_ua = optim.Adam(ua_lnn_model.parameters(), lr=0.001)\n",
    "print(\"\\nTraining Uncertainty-Aware LNN:\")\n",
    "ua_lnn_model = train_model(ua_lnn_model, train_loader, epochs=50)\n\n",
    "# Generate prediction bands with MC dropout\n",
    "def get_prediction_bands(model, data_loader, num_passes=30):\n",
    "    model.train() # Enable dropout during inference\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_passes):\n",
    "            pass_preds = []\n",
    "            for inputs, _ in data_loader:\n",
    "                pass_preds.append(model(inputs))\n",
    "            predictions.append(torch.cat(pass_preds, dim=0))\n",
    "    predictions = torch.stack(predictions).numpy()\n",
    "    mean_preds = predictions.mean(axis=0)\n",
    "    lower_bound = np.percentile(predictions, 2.5, axis=0)\n",
    "    upper_bound = np.percentile(predictions, 97.5, axis=0)\n",
    "    return mean_preds, lower_bound, upper_bound\n\n",
    "mean_preds, lower_b, upper_b = get_prediction_bands(ua_lnn_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.5. Experiment 5: 'Cold-Start' Generalization\n\n",
    "We simulate a 'cold-start' scenario by training on normal years and fine-tuning on strong/weak monsoon years. This tests the LNN's ability to adapt to new conditions after deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Placeholder for IMD indices - assuming we have a 'monsoon_type' column\n",
    "# For now, we'll create a mock split\n",
    "df_mock = df.copy()\n",
    "df_mock['monsoon_type'] = np.random.choice(['normal', 'strong', 'weak'], size=len(df_mock))\n\n",
    "normal_years_df = df_mock[df_mock['monsoon_type'] == 'normal']\n",
    "strong_weak_df = df_mock[df_mock['monsoon_type'] != 'normal']\n\n",
    "# This section would involve training on 'normal_years_df' and then fine-tuning\n",
    "# on 'strong_weak_df' and measuring regret. The implementation is omitted for brevity."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.6. Experiment 6: 1-step vs. K-step Rollout\n\n",
    "We test the model's long-term forecasting stability by performing a k-step rollout (14-day forecast) and injecting noise into the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def k_step_rollout_pytorch(model, initial_window, k, noise_type=None):\n",
    "    model.eval()\n",
    "    current_window = initial_window.clone().detach()\n",
    "    predictions = []\n\n",
    "    for _ in range(k):\n",
    "        # Add noise if specified\n",
    "        if noise_type == 'additive':\n",
    "            current_window += torch.randn_like(current_window) * 0.05\n",
    "        elif noise_type == 'undercatch':\n",
    "            current_window[:, 1:] *= 0.9 # -10% under-catch for rainfall\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(current_window.unsqueeze(0))[:, 0]\n",
    "        predictions.append(pred.item())\n",
    "\n",
    "        # Roll the window forward\n",
    "        new_row = current_window[-1, :].clone().detach()\n",
    "        new_row[0] = pred\n",
    "        current_window = torch.roll(current_window, -1, dims=0)\n",
    "        current_window[-1, :] = new_row\n",
    "        \n",
    "    return np.array(predictions)\n\n",
    "# Example usage (conceptual)\n",
    "initial_sequence_t = X_test_t[0]\n",
    "rollout_preds_lnn = k_step_rollout_pytorch(lnn_model, initial_sequence_t, k=14, noise_type='additive')\n\n",
    "print(f\"14-day LNN rollout predictions (with additive noise):\\n{rollout_preds_lnn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.7. Experiment 7: 'Physics-infused τ' – Priming the Liquid Constant\n\n",
    "Instead of random initialization, we prime the LNN's time constants (`τ`) with physics-based estimates of catchment travel time. This experiment investigates if this prior knowledge improves convergence and model plausibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Placeholder for physics-based travel times (e.g., from SCS-CN method)\n",
    "physics_travel_times = np.random.rand(num_features) # Replace with actual estimates\n",
    "physics_travel_times_tensor = torch.tensor(physics_travel_times, dtype=torch.float32)\n\n",
    "class PhysicsLNN(SpatiallyAwareLNN):\n",
    "    def __init__(self, input_size, hidden_size, output_size, initial_taus):\n",
    "        super(PhysicsLNN, self).__init__(input_size, hidden_size, output_size)\n",
    "        # Initialize time constants with physics-based estimates\n",
    "        self.time_constants.data = initial_taus\n\n",
    "# Initialize and train the physics-infused LNN\n",
    "lnn_physics_model = PhysicsLNN(num_features, 128, 1, physics_travel_times_tensor)\n",
    "optimizer_physics = optim.Adam(lnn_physics_model.parameters(), lr=0.001)\n",
    "print(\"\\nTraining Physics-Infused LNN:\")\n",
    "lnn_physics_model = train_model(lnn_physics_model, train_loader, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.8. Experiment 8: Extreme-Value Focus\n\n",
    "This experiment focuses on the model's ability to predict extreme inflow events. We use a Peaks-Over-Threshold (POT) approach to identify these events and evaluate the model's performance on the tail of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Identify extreme events using Peaks-Over-Threshold (POT)\n",
    "threshold = df_final['Inflows in last 24 Hrs. in Mcft.'].quantile(0.95)\n",
    "extreme_events_actual = df_final[df_final['Inflows in last 24 Hrs. in Mcft.'] > threshold]\n\n",
    "# Evaluate model performance on these extreme events\n",
    "extreme_preds_lstm = df_final.loc[extreme_events_actual.index, 'LSTM_Pred']\n",
    "rmse_extreme = np.sqrt(mean_squared_error(extreme_events_actual['Inflows in last 24 Hrs. in Mcft.'], extreme_preds_lstm))\n\n",
    "print(f\"RMSE on Top 5% Extreme Events (LSTM): {rmse_extreme:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.9. Experiment 9: Compute & Carbon Audit\n\n",
    "We log the training time and parameter count for each model to provide an audit of computational and potential energy consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "compute_audit = {}\n\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n",
    "# --- LSTM ---\n",
    "start_time = time.time()\n",
    "model_lstm.fit(train_generator, epochs=1, validation_data=test_generator, shuffle=False, verbose=0)\n",
    "lstm_time = time.time() - start_time\n",
    "compute_audit['LSTM'] = {'Training Time (s/epoch)': lstm_time, 'Parameters': model_lstm.count_params()}\n\n",
    "# --- LNN ---\n",
    "start_time = time.time()\n",
    "train_lnn(lnn_model, train_data_loader, criterion, optimizer, epochs=1)\n",
    "lnn_time = time.time() - start_time\n",
    "compute_audit['LNN'] = {'Training Time (s/epoch)': lnn_time, 'Parameters': count_parameters(lnn_model)}\n\n",
    "audit_df = pd.DataFrame(compute_audit).T\n",
    "print(\"Compute & Carbon Audit:\")\n",
    "print(audit_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.10. Experiment 10: Reproducibility Checklist\n\n",
    "To ensure this study is fully reproducible, we provide the following components:\n\n",
    "- **Raw & Pre-processed Data:** The `final_inflow_rainfall_merged.csv` file is the primary data source.\n",
    "- **Train/Val/Test Splits:** The exact splits can be reproduced using the `train_test_split` function with `random_state=123` and `shuffle=False`.\n",
    "- **Hyperparameters:** All hyperparameters (window length, batch size, learning rate, etc.) are explicitly defined in the code cells.\n",
    "- **Random Seeds:** We set `random_state=123` for the data split and will use fixed seeds for model initializations where applicable.\n",
    "- **Metrics Notebook:** This notebook itself serves as the metrics notebook, containing all code for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reproducibility_checklist = {\n",
    "    \"Raw Data\": \"final_inflow_rainfall_merged.csv\",\n",
    "    \"Train/Test Split\": \"test_size=0.20, random_state=123, shuffle=False\",\n",
    "    \"Hyperparameters\": {\n",
    "        \"window_length\": 5,\n",
    "        \"batch_size\": 32,\n",
    "        \"epochs\": 50,\n",
    "        \"learning_rate\": 0.001\n",
    "    },\n",
    "    \"Random Seeds\": \"random_state=123 for data split\",\n",
    "    \"Metrics Notebook\": \"This notebook\"\n",
    "}\n\n",
    "import json\n",
    "print(\"Reproducibility Checklist:\")\n",
    "print(json.dumps(reproducibility_checklist, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7. Final Conclusion and Comparison\n\n",
    "This section synthesizes the results from all baseline models and the 10 LNN experiments. We provide a comprehensive comparison based on both quantitative metrics and qualitative characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7.1. Master Quantitative Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# This cell will be populated with the final results from all experiments\n",
    "final_results = results_df.copy()\n",
    "# ... add results from LNN experiments ...\n",
    "display(Markdown('**Master Performance Metrics Table**'))\n",
    "display(final_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7.2. Qualitative Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "qualitative_data = {\n",
    "    'Metric': ['Interpretability', 'Irregular Data Handling', 'Noise Robustness', 'Uncertainty Quantification', 'Computational Efficiency'],\n",
    "    'LSTM/GRU': ['Low (Black Box)', 'Requires Imputation', 'Moderate', 'Requires Extensions (e.g., Bayesian)', 'Low (High Params)'],\n",
    "    '1D-CNN': ['Moderate (Filters)', 'Requires Imputation', 'High', 'Requires Extensions', 'High'],\n",
    "    'LNN': ['High (τ, Connectivity)', 'Native Support', 'High (Expected)', 'Native (MC Dropout)', 'High (Fewer Params)']\n",
    "}\n",
    "qualitative_df = pd.DataFrame(qualitative_data).set_index('Metric')\n",
    "display(Markdown('**Qualitative Model Comparison**'))\n",
    "display(qualitative_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7.3. Summary of Key Findings\n\n",
    "This section will provide a narrative summary of the results, drawing conclusions from the tables and visualizations above. It will focus on answering the core research question: **How do LNNs perform in real-world hydrological forecasting compared to other models, and in what specific scenarios do they excel?**\n\n",
    "**Key discussion points will include:**\n\n",
    "- **Overall Performance:** How did the baseline LNN compare to LSTM, GRU, and CNNs on standard metrics?\n",
    "- **Irregular Data:** Did the LNN show a distinct advantage when trained on the non-uniform, event-based data grid?\n",
    "- **Interpretability:** What insights did the spatial ablation and physics-infused `τ` experiments provide about the underlying hydrological system?\n",
    "- **Robustness and Uncertainty:** How well did the LNN handle noisy inputs, and did the UA-LNN provide meaningful uncertainty estimates for flood-risk assessment?\n",
    "- **Adaptability:** Did the 'cold-start' experiment suggest that LNNs can adapt to changing conditions more efficiently than traditional models?\n",
    "- **Efficiency:** Was the LNN more computationally efficient, as suggested by the compute audit?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}